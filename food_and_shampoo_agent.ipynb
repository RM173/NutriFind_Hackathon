{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3.1 Rag Agent with LlamaIndex\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/ytang07/ai_agents_cookbooks/blob/main/llamaindex/llama31_8b_rag_agent.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "This notebook will walk you through building a LlamaIndex ReactAgent using Llama 3.1 70b. We will be using [OctoAI](https://octo.ai) as our embeddings and llm provider.\n",
    "\n",
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -qU llama-index llama-index-llms-openai llama-index-readers-file octoai llama-index-llms-octoai llama-index-embeddings-octoai llama-index-embeddings-openai llama-index-llms-openai-like\n",
    "\n",
    "# ! pip freeze | grep llama-index-core\n",
    "# ! pip freeze | grep embeddings-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional imports\n",
    "import logging\n",
    "from httpx import HTTPStatusError, ConnectError\n",
    "\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "logging.getLogger().setLevel(logging.WARNING)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup API Keys\n",
    "To run the rest of the notebook you will need access to an OctoAI API key. You can sign up for an account [here](https://octoai.cloud/). If you need further guidance you can check OctoAI's [documentation page](https://octo.ai/docs/getting-started/how-to-create-octoai-access-token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "from getpass import getpass\n",
    "# environ[\"OCTOAI_API_KEY\"] = getpass(\"Input your OCTOAI API key: \")\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OCTOAI_API_KEY = environ[\"OCTOAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and setup LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.embeddings.octoai import OctoAIEmbedding\n",
    "from llama_index.core import Settings as LlamaGlobalSettings\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "\n",
    "# Set the default model to use for embeddings\n",
    "LlamaGlobalSettings.embed_model = OctoAIEmbedding()\n",
    "\n",
    "# Create an llm object to use for the QueryEngine and the ReActAgent\n",
    "llm = OpenAILike(\n",
    "    model=\"meta-llama-3.1-70b-instruct\",\n",
    "    api_base=\"https://text.octoai.run/v1\",\n",
    "    api_key=environ[\"OCTOAI_API_KEY\"],\n",
    "    context_window=40000,\n",
    "    is_function_calling_model=True,\n",
    "    is_chat_model=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes loaded: False\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"./storage/food\"\n",
    "    )\n",
    "    food_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"./storage/shampoo\"\n",
    "    )\n",
    "    shampoo_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    index_loaded = True\n",
    "except:\n",
    "    index_loaded = False\n",
    "print(\"Indexes loaded:\", index_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the point we create our vector indexes, by calculating the embedding vectors for each of the chunks. You only need to run this once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 16/16 [00:00<00:00, 1247.77it/s]\n",
      "Generating embeddings: 100%|██████████| 16/16 [00:02<00:00,  7.42it/s]\n",
      "Parsing nodes: 100%|██████████| 6/6 [00:00<00:00, 631.85it/s]\n",
      "Generating embeddings: 100%|██████████| 6/6 [00:00<00:00,  7.27it/s]\n"
     ]
    }
   ],
   "source": [
    "if not index_loaded:\n",
    "    # load data\n",
    "    food_docs = SimpleDirectoryReader(\n",
    "        input_files=[\"./food/foodInfo.pdf\"]\n",
    "    ).load_data()\n",
    "\n",
    "    # build index\n",
    "    food_index = VectorStoreIndex.from_documents(food_docs, show_progress=True)\n",
    "\n",
    "    # persist index\n",
    "    food_index.storage_context.persist(persist_dir=\"./storage/food\")\n",
    "\n",
    "    # load data\n",
    "    shampoo_docs = SimpleDirectoryReader(\n",
    "        input_files=[\"./shampoo/shampooInfo.pdf\"]\n",
    "    ).load_data()\n",
    "\n",
    "    # build index\n",
    "    shampoo_index = VectorStoreIndex.from_documents(shampoo_docs, show_progress=True)\n",
    "\n",
    "    # persist index\n",
    "    shampoo_index.storage_context.persist(persist_dir=\"./storage/shampoo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the query engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_engine = food_index.as_query_engine(similarity_top_k=3, llm=llm)\n",
    "shampoo_engine = shampoo_index.as_query_engine(similarity_top_k=3, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define the query engines as tools that will be used by the agent.\n",
    "\n",
    "As there is a query engine per document we need to also define one tool for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=food_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"food\",\n",
    "            description=(\n",
    "                \"Provides information about ingredients in food. \"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    QueryEngineTool(\n",
    "        query_engine=shampoo_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"shampoo\",\n",
    "            description=(\n",
    "                \"Provides information about ingredients in shampoo. \"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Agent\n",
    "Now we have all the elements to create a LlamaIndex ReactAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent.from_tools(\n",
    "    query_engine_tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_turns=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can interact with the agent and ask a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step c5f13dff-5fb0-45bc-ba99-7fa205c7b048. Step input: Tell me about the Sodium Laureth Sulfate ingredients that is in some shampoo?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: shampoo\n",
      "Action Input: {'input': 'Sodium Laureth Sulfate ingredients in some shampoo'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Sodium Laureth Sulfate (SLES) is a milder alternative to Sodium Lauryl Sulfate (SLS), providing good cleansing and foaming properties while being less irritating to the skin and hair. It is currently the most widely and largely used surfactant in shampoos.\n",
      "\u001b[0m> Running step 576c44b3-3a9a-421c-a0e4-d8f2e16ca8ce. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: Sodium Laureth Sulfate (SLES) is a mild alternative to Sodium Lauryl Sulfate (SLS), providing good cleansing and foaming properties while being less irritating to the skin and hair. It is currently the most widely and largely used surfactant in shampoos.\n",
      "\u001b[0mSodium Laureth Sulfate (SLES) is a mild alternative to Sodium Lauryl Sulfate (SLS), providing good cleansing and foaming properties while being less irritating to the skin and hair. It is currently the most widely and largely used surfactant in shampoos.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Tell me about the Sodium Laureth Sulfate ingredients that is in some shampoo?\")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aacb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
